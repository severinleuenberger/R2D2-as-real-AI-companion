# R2D2 Face Recognition Testing Suite

**Date:** December 6, 2025  
**Status:** ✅ Implementation Ready  
**Platform:** NVIDIA Jetson AGX Orin 64GB with OAK-D Lite Camera

---

## Overview

This directory contains standalone (non-ROS) scripts for training and testing personal face recognition for Severin. Uses OpenCV's LBPH (Local Binary Pattern Histograms) face recognizer for CPU-efficient, fast recognition on ARM.

## Quick Start (3 Steps)

### Step 1: Capture Training Data
```bash
cd ~/dev/r2d2/tests/face_recognition
source ~/depthai_env/bin/activate
export OPENBLAS_CORETYPE=ARMV8

python3 1_capture_training_data.py
```

**What happens:**
- Script guides you through 4 stages (bright, dim, side angle, varied distance)
- Each stage: 10-15 seconds of video, camera detects faces automatically
- Extracts 100×100 face crops from each detection
- Saves to: `~/dev/r2d2/data/face_recognition/severin/`
- **Expected:** 50-150 total images after all stages

**Interaction:**
- Press ENTER to start each stage
- Face detection boxes appear in real-time on screen
- Counter shows: "Faces: 2 | Saved this stage: 15"
- Press 'q' to skip to next stage, Ctrl+C to exit

---

### Step 2: Train Recognizer Model
```bash
python3 2_train_recognizer.py
```

**What happens:**
- Loads all captured face images from `~/dev/r2d2/data/face_recognition/severin/`
- Trains LBPH recognizer (Local Binary Pattern Histograms)
- Saves model to: `~/dev/r2d2/data/face_recognition/models/severin_lbph.xml`
- **Training time:** ~3-5 seconds on Jetson
- **Model size:** ~50-100 KB

**Output:**
```
✓ Loaded 120 training images
✓ Training complete
✓ Model saved successfully (87432 bytes)

Next step: Run 3_test_recognizer_demo.py to test recognition.
```

---

### Step 3: Test Recognition at Multiple Distances
```bash
python3 3_test_recognizer_demo.py
```

**What happens:**
- Tests recognition at 4 distances: 1m, 2m, 3m, 5m
- For each distance, captures ~10 seconds of live video
- Detects faces and runs LBPH recognition on each
- Logs results: "Severin recognized (confidence=92.1)" or "Unknown (confidence=65.3)"
- Outputs: Recognition rate, average confidence per distance

**Expected output:**
```
======================================================================
DISTANCE STAGE: 1m
======================================================================
Testing for 10 seconds...

Frame    1 | Severin recognized (confidence=91.2)
Frame    2 | Severin recognized (confidence=89.5)
Frame    3 | Unknown (confidence=65.3)
Frame    4 | Severin recognized (confidence=92.1)
...

--- Stage Summary (at 1m) ---
Frames captured: 300
Frames with faces: 28
Severin recognized: 25/28
Recognition rate: 89.3%
Avg Severin confidence: 90.8
```

---

## File Structure

```
~/dev/r2d2/tests/face_recognition/
├── 1_capture_training_data.py    # Interactive capture script
├── 2_train_recognizer.py          # Train LBPH model
├── 3_test_recognizer_demo.py      # Test recognition at distances
└── README.md                       # This file

~/dev/r2d2/data/face_recognition/
├── severin/                        # Training images (generated by step 1)
│   ├── 20251206_120530_bright_direct_000.jpg
│   ├── 20251206_120531_bright_direct_001.jpg
│   └── ... (100+ images)
└── models/                         # Trained models (generated by step 2)
    └── severin_lbph.xml          # Trained LBPH model
```

---

## Understanding the Results

### Confidence Scores

LBPH produces a **distance metric** in face space. Lower is better:

| Confidence | Interpretation | Action |
|-----------|-----------------|--------|
| 0-40      | Very high match | Definitely Severin |
| 40-70     | Good match | Probably Severin |
| 70-100    | Weak match | Probably not Severin |
| 100+      | Poor match | Definitely not Severin |

**Recognition Threshold:** Default is 70 (tunable in script)

### Recognition Rate by Distance

Expected performance (depends heavily on training data quality):

| Distance | Expected Recognition Rate | Notes |
|----------|--------------------------|-------|
| 1m | 80-95% | Best conditions, clear face |
| 2m | 70-85% | Face still large enough |
| 3m | 50-70% | Face becomes small, lighting matters |
| 5m | 20-40% | Face very small, difficult recognition |

**Improve recognition at distance:**
1. Train with more images from that distance
2. Improve lighting in training data
3. Train with side angles and varied expressions
4. Consider increasing face detection minSize

---

## Troubleshooting

### Issue: "LBPH model not found" when running step 3
**Solution:** Run step 2 (training) first. Model must exist before recognition test.

### Issue: No faces detected during capture
**Solution:**
- Check camera is working: `python3 -c "import depthai; print(len(depthai.XLinkConnection.getAllConnectedDevices()))"`
- Ensure good lighting
- Stand 1-2 meters from camera for initial detection
- Haar Cascade sometimes misses at odd angles; move slowly

### Issue: Low recognition rate (< 50% at 1m)
**Possible causes:**
- Too few training images (need 50+, better with 100+)
- Training images don't match test conditions (lighting, angle)
- Camera needs adjustment (focus, resolution)

**Solutions:**
1. Retrain with more diverse images (different angles, lighting)
2. Run demo in same lighting conditions as training
3. Lower the recognition threshold (change `self.recognition_threshold = 70.0` to 80-90)

### Issue: Script hangs or camera doesn't initialize
**Solution:**
- Check environment setup:
  ```bash
  source ~/depthai_env/bin/activate
  export OPENBLAS_CORETYPE=ARMV8
  ```
- Verify OAK-D is connected: `lsusb | grep Movidius`
- Restart device if needed: `pkill -9 python3 && sleep 2`

---

## Performance Notes

### CPU/Memory Usage
- **Capture script:** ~20-25% CPU (camera I/O + face detection), ~100 MB memory
- **Training script:** ~30-40% CPU for 3-5 seconds (one-time), ~150 MB memory
- **Recognition script:** ~10-15% CPU when faces present (~5ms per recognition)

### Frame Rate
- **Camera:** 30 FPS native
- **Face detection:** ~13 FPS effective (Haar Cascade + downscaling overhead)
- **Face recognition:** ~25-30 FPS (LBPH is very fast)

---

## Next Steps

Once these scripts work well:

1. **ROS 2 Integration:** Extend `image_listener.py` to include LBPH recognition
   - New publisher: `/r2d2/perception/person_id` (String)
   - New publisher: `/r2d2/perception/face_confidence` (Float32)
   - See `04_FACE_RECOGNITION_INTEGRATION.md` for details

2. **Improve Recognition:**
   - Collect more training data (200+ images)
   - Add other people's faces as "unknown" class
   - Tune Haar Cascade parameters for better detection

3. **Distance Robustness:**
   - Train with images from 1m, 2m, 3m distances specifically
   - Use super-resolution or upscaling for small faces at distance
   - Consider multi-scale approach (detect at different scales)

---

## Key Parameters (Customizable)

In `3_test_recognizer_demo.py`:
```python
self.recognition_threshold = 70.0  # Adjust if confidence is too high/low
```

In `1_capture_training_data.py`:
```python
duration_seconds=10  # Increase for more images per stage
```

In `2_train_recognizer.py`:
```python
grid_x=8, grid_y=8  # LBPH grid resolution (smaller = faster, less accurate)
```

---

## Author Notes

- LBPH was chosen for its simplicity and CPU efficiency on ARM
- Could be extended with deep learning (FaceNet, ArcFace) for better accuracy, but requires GPU
- Current implementation prioritizes reliability and reproducibility on Jetson AGX Orin
- All training data stored locally; model is re-trainable anytime

---

**Questions?** See `~/dev/r2d2/00_INTERNAL_AGENT_NOTES.md` for environment setup.
